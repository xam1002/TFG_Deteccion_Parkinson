{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de datos y obtención de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de bibliotecas\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import glob\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento de vídeo\n",
    "Se realiza un procesado en los vídeos para extraer datos relevantes que sirvan para detectar el Parkinson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funciones para leer los vídeos y mostrar fotogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se obtienen los fotogramas de uno en uno del vídeo pasado por parámetro.\n",
    "\n",
    "Parámetros:\n",
    " - vd: vídeo del que obtener los fotogramas.\n",
    " \n",
    "Retorno:\n",
    " - frame: fotograma actual del vídeo.\n",
    "'''\n",
    "def frameVideo(vd):\n",
    "    vc = cv2.VideoCapture(vd)\n",
    "\n",
    "    if (vc.isOpened()==False):\n",
    "        print(\"Error\")\n",
    "    else:\n",
    "        while(vc.isOpened()):\n",
    "            ret,frame = vc.read()\n",
    "            if ret:\n",
    "                yield frame\n",
    "            else:\n",
    "                vc.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se muestra el fotograma pasado por parámetro.\n",
    "\n",
    "Parámetros:\n",
    " - frame: fotograma que se desea mostrar.\n",
    "'''\n",
    "def mostrarFrame(frame):\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(frame)\n",
    "    plt.title(\"Prueba\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se obtiene el fotograma deseado del vídeo pasado por parámetro. \n",
    "\n",
    "Parámetros:\n",
    " - vid: vídeo del que obtener el fotograma.\n",
    " - nframe: la posición del fotograma que se desea obtener.\n",
    " \n",
    "Retorno:\n",
    " - frame: fotograma deseado del vídeo.\n",
    "'''\n",
    "def obtenerFrame(vid,nframe):\n",
    "    vc = cv2.VideoCapture(vid)\n",
    "\n",
    "    if (vc.isOpened()==False):\n",
    "        print(\"Error\")\n",
    "        return None\n",
    "    else:\n",
    "        for i in range(nframe):\n",
    "            ret,frame = vc.read()\n",
    "        \n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se crea un objeto de vídeo para guardar los fotogramas pasados por parámetro.\n",
    "\n",
    "Parámetros:\n",
    " - ruta: ruta donde se desea guardar el objeto de vídeo creado.\n",
    " - frames: fotogramas que se desean guardar.\n",
    " - encoder: codificador para guardar los fotogramas. Por defecto: cv2.VideoWriter_fourcc(*'DIVX').\n",
    " - fps: los fotogramas por segundo que tendrá el vídeo creado. Por defecto: 15. \n",
    "'''\n",
    "def grabarFrames(ruta,frames,encoder=cv2.VideoWriter_fourcc(*'DIVX'),fps=15):\n",
    "    for i in frames:\n",
    "        if i is not None:\n",
    "            h,z=i.shape[:2]\n",
    "            break\n",
    "    size=(z,h)\n",
    "    out = cv2.VideoWriter(ruta,encoder,fps,size)\n",
    "    \n",
    "    for i in frames:\n",
    "        out.write(i)\n",
    "    \n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se redimensiona y se muestra, si se desea, el fotograma pasado por parámetro.\n",
    "\n",
    "Parámetros:\n",
    " - frame: fotograma que se quiere redimensionar.\n",
    " - width: nueva anchura del fotograma. Por defecto: 480.\n",
    " - height: nueva altura del fotograma. Por defecto: 480.\n",
    " - show: valor booleano para indicar si se desea mostrar o no el fotograma redimensionado. Por defecto: False.\n",
    "'''\n",
    "def resize_and_show(frame,width=480,height=480,show=False):\n",
    "    h, w = frame.shape[:2]\n",
    "    if h < w:\n",
    "        img = cv2.resize(frame, (width, math.floor(h/(w/width))))\n",
    "    else:\n",
    "        img = cv2.resize(frame, (math.floor(w/(h/height)), height))\n",
    "    \n",
    "    if show:\n",
    "        mostrarFrame(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Marcado de los puntos en la mano\n",
    "Para cada fotograma del vídeo, se marcan los puntos de la mano. Esto servirá para conocer la posición de los dedos en cada insante del vídeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se marcan los puntos de la mano del fotograma pasado por parámetro.\n",
    "\n",
    "Parámetros:\n",
    " - frame: fotograma con la mano en donde indicar los puntos.\n",
    " - static: modo de imagen estático. Por defecto: True.\n",
    " - max_num_hands: número máximo de manos. Por defecto: 1.\n",
    " - min_detection_confidence: mímina detección de confianza. Por defecto: 0.\n",
    " - show: valor booleano para indicar si se desea redimensionar y mostrar o no el fotograma. Por defecto: False.\n",
    " \n",
    "Retorno:\n",
    " - annotated_frame: fotograma con la mano.\n",
    " - results.mulit_hand_landmarks: puntos de la mano.\n",
    "'''\n",
    "def frameMano(frame, static=True,max_num_hands=1,min_detection_confidence=0,show=False):\n",
    "    with mp_hands.Hands(static_image_mode=static,max_num_hands=max_num_hands, min_detection_confidence=min_detection_confidence) as hands:\n",
    "        results = hands.process(cv2.flip(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), 1))\n",
    "        frame_hight, frame_width, _ = frame.shape\n",
    "        annotated_frame = cv2.flip(frame.copy(), 1)\n",
    "        \n",
    "        if results.multi_hand_landmarks is None:\n",
    "            return annotated_frame,None\n",
    "        \n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # Print index finger tip coordinates.\n",
    "            print(\n",
    "                f'Index finger tip coordinate: (',\n",
    "                f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x * frame_width}, '\n",
    "                f'{hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y * frame_hight})'\n",
    "            )\n",
    "            mp_drawing.draw_landmarks(annotated_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "        if show:\n",
    "            resize_and_show(cv2.flip(annotated_frame, 1))\n",
    "        \n",
    "        return annotated_frame,results.multi_hand_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo de las distancias\n",
    "Se calculan las distancias para poder extraer las características. Sin embargo, estas distancias no son las definitivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se calcula la distancia entre el punto del dedo índice y el punto del dedo pulgar.\n",
    "\n",
    "Parámetros:\n",
    " - mano: lista con los puntos de la mano.\n",
    " \n",
    "Retorno:\n",
    " - np.linalg.norm(p4-p8): distancia entre los puntos.\n",
    "'''\n",
    "def calcularDistancia(mano):\n",
    "    x4=mano[0].landmark[4].x\n",
    "    y4=mano[0].landmark[4].y\n",
    "    x8=mano[0].landmark[8].x\n",
    "    y8=mano[0].landmark[8].y\n",
    "    \n",
    "    if x4<0 or y4<0 or x8<0 or y8<0:\n",
    "        return None\n",
    "    \n",
    "    p4=np.array((x4,y4))\n",
    "    p8=np.array((x8,y8))\n",
    "    \n",
    "    return np.linalg.norm(p4-p8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se calcula la distancia de todos los puntos de los dedos índice y pulgar \n",
    "de la mano pasados por parámetro.\n",
    "\n",
    "Parámetros:\n",
    " - manos: estructura con los puntos de la mano.\n",
    " \n",
    "Retorno:\n",
    " - dist: lista de las distancias de los puntos de la mano.\n",
    "'''\n",
    "def calcularDistanciasVideo(manos):\n",
    "    dist = []\n",
    "    for i in manos:\n",
    "        if i is not None:\n",
    "            dist.append(calcularDistancia(i))\n",
    "        \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de los datos\n",
    "Normalmente, los datos extraídos no son perfectos, pues podrían contener ruido que los empeoren. En este caso, no hay excesivo ruido, pero es necesario aun así aplicar un filtrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrado y representación de las distancias\n",
    "Para cada vídeo, se realiza el cálculo de todas las distancias y se muestran en forma de gráfica.\n",
    "\n",
    "Además, para suavizar un problema de la biblioteca en el que los puntos cambian sin haberse producido movimiento de la mano, se aplica el filtro de Savitzky–Golay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Se obtienen la gráfica de las distancias obtenidas.\n",
    "\n",
    "Parámetros:\n",
    " - ruta: lugar donde se encuentra el vídeo.\n",
    " - guardar: lugar donde guardar la gráfica. Por defecto: None.\n",
    " \n",
    "Retorno:\n",
    " - dist: lista de las distancias del dedo índice al dedo pulgar. \n",
    "'''\n",
    "def analizarVideo(ruta,guardar=None):\n",
    "    manos=[]\n",
    "    for i in frameVideo(ruta):\n",
    "        frame,mano = frameMano(i)\n",
    "        manos.append(mano)\n",
    "\n",
    "    dist = calcularDistanciasVideo(manos)\n",
    "    \n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure(figsize=(30, 20))\n",
    "    ax = plt.axes()\n",
    "    x = np.linspace(0,len(dist), len(dist))\n",
    "    plt.plot(x, dist)\n",
    "    plt.plot(x,scipy.signal.savgol_filter(dist, 3, 1))\n",
    "    dist = scipy.signal.savgol_filter(dist, 3, 1)\n",
    "    if guardar is not None:\n",
    "        plt.savefig(\"../Outputs/\"+guardar)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de datos\n",
    "Se obtienen los datos de todos los vídeos para poder obtener características a partir de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\LVAROA~1\\AppData\\Local\\Temp/ipykernel_17572/3535809964.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minicio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdatos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../TFG/Videos/*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "inicio = time.time()\n",
    "datos = []\n",
    "for i in glob.glob(\"../TFG/Videos/*\"):\n",
    "    aux = i.split(\"/\")[-1].split(\"\\\\\")[-1]\n",
    "    print(\"\\n\", aux, \"\\n\")\n",
    "    datos.append(analizarVideo(i,guardar=\"../TFG/Outputs/Graficas/\"+aux+\"v11.png\"))\n",
    "    \n",
    "fin = time.time()\n",
    "print(\"Tiempo total:\", fin - inicio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtención de características\n",
    "A partir de los datos obtenidos y de los proporcionados en el nombre de los vídeos, se extraen características que sirvan para poder indentificar el Parkinson.\n",
    "Las características proporcionadas en el nombre de los vídeos son:\n",
    "- Si la mano es la derecha o la izquierda.\n",
    "- El sexo de la persona.\n",
    "- La edad de la persona.\n",
    "\n",
    "Las características calculadas son:\n",
    "- Amplitud de la pinza.\n",
    "- Tiempo que se tarda en abrir la pinza.\n",
    "- Velocidad a la que se abre la pinza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtención de las características proporcionadas\n",
    "A partir del nombre de cada vídeo, se obtienen algunas de las características. Estas características están escritas como letras, pero se realiza una conversión a forma numérica, donde se obtiene:\n",
    "- La mano de la persona:\n",
    "    - Derecha (D) -> 0\n",
    "    - Izquierda (I) -> 1\n",
    "- Sexo de la persona:\n",
    "    - Hombre (H) -> 0\n",
    "    - Mujer (M) -> 1\n",
    "\n",
    "La edad permanece con tipo numérico. Además, para saber si una persona tiene Parkinson o no, que también se recoge del nombre del vídeo, se añade una columna de forma numérica. Si la persona no tiene Parkinson, se simbolizará con el número 0, en caso opuesto, con el número 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manos_der_izq=[]\n",
    "parkinson=[]\n",
    "sexo=[]\n",
    "edad=[]\n",
    "for i in glob.glob(\"..\\TFG\\Videos\\*\"):\n",
    "    aux = i.split(\"\\\\\")[-1]\n",
    "    if aux.split(\"_\")[-1].split(\" \")[0][0] == 'D':\n",
    "        manos_der_izq.append(0)\n",
    "    elif aux.split(\"_\")[-1].split(\" \")[0][0] == 'I':\n",
    "        manos_der_izq.append(1)\n",
    "    if aux.split(\" \")[-1].split(\".\")[0].split(\"-\")[0] == '(H':\n",
    "        sexo.append(0)\n",
    "    elif aux.split(\" \")[-1].split(\".\")[0].split(\"-\")[0] == '(M':\n",
    "        sexo.append(1)\n",
    "    edad.append(aux.split(\" \")[-1].split(\".\")[0].split(\"-\")[1].split(')')[0])\n",
    "    if \"CONTROL\" in aux: \n",
    "        parkinson.append(0)\n",
    "    else:\n",
    "        parkinson.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtención de la amplitud\n",
    "Se recogen los máximos y los mínimos de las 5 primeras aperturas y de las 5 últimas. A continuación, se calcula la diferencia que las separa. Esta diferencia será algo más real que la obtenida anteriormente, ya que se tiene en cuenta la distancia desde las yemas de los dedos en vez desde el centro de los dedos, donde está el punto de la biblioteca de Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diferencias=[]\n",
    "maximos=[]\n",
    "minimos=[]\n",
    "j=-1\n",
    "salir = False\n",
    "for d in datos:\n",
    "    i = 1\n",
    "    minimo=[]\n",
    "    maximo=[]\n",
    "    diferencia=[]\n",
    "    media = np.mean(d)\n",
    "    j+=1\n",
    "    for f in range(10):\n",
    "        min_actual = float('inf')\n",
    "        max_actual = 0\n",
    "        if f == 5:\n",
    "            i = -1\n",
    "        while d[i] > media:\n",
    "            if f == 5:\n",
    "                i-=1\n",
    "            else:\n",
    "                i+=1\n",
    "        while d[i] > media or not salir:\n",
    "            if d[i] < media and d[i] < min_actual:\n",
    "                min_actual = d[i] \n",
    "            if d[i] > media:\n",
    "                salir = True\n",
    "                if d[i] > max_actual:\n",
    "                    max_actual = d[i]\n",
    "            if f >= 5:\n",
    "                i-=1\n",
    "            else:\n",
    "                i+=1\n",
    "        salir = False\n",
    "        \n",
    "        minimo.append(min_actual)\n",
    "        maximo.append(max_actual)\n",
    "        diferencia.append(max_actual - min_actual)\n",
    "        \n",
    "    diferencias.append(diferencia)\n",
    "    minimos.append(minimo)\n",
    "    maximos.append(maximo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtención del tiempo\n",
    "Con los máximos y mínimos obtenidos en el paso anterior, se puede conocer cuántos fotogramas hay entre ambos, para conocer la velocidad. Para ello, se obtiene la posición que ocupan cada máximo y mínimo para poder restarlas y extraer el número de posiciones (i. e. fotogramas) que los separan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiempos=[]\n",
    "for m in range(len(minimos)):\n",
    "    mini = []\n",
    "    maxi = []\n",
    "    for a in range(10):\n",
    "        mini.append(list(datos[m]).index(minimos[m][a]))\n",
    "        maxi.append(list(datos[m]).index(maximos[m][a]))\n",
    "\n",
    "    resta = []\n",
    "    for m1, m2 in zip(mini,maxi):\n",
    "        resta.append(abs(m1-m2))\n",
    "    tiempos.append(resta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtención de la velocidad\n",
    "Una vez obtenidas las características de amplitud y tiempo, se puede calcular la velocidad realizando la división de la amplitud realizada entre el tiempo que se ha tardado en realizarla.\n",
    "\n",
    "Este cálculo se realiza directamente en la inserción de los datos en el dataframe, unas celdas más abajo. Esto es debido a que es importante que la velocidad tenga en cuenta la amplitud de la pinza normalizada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalización de las amplitudes\n",
    "Teniendo en cuenta que no todos los vídeos están grabados a la misma distancia de la cámara, las amplitudes deberán estar normalizadas para que todas estén al mismo nivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Se obtienen los datos de la lista normalizados con respecto al máximo y mínimo de cada vídeo.\n",
    "\n",
    "Parámetros\n",
    " - lista: estructura con los datos que se van a normalizar.\n",
    " - maximo: punto máximo que se ha alcanzado.\n",
    " - minimo: punto mínimo que se ha alcanzado.\n",
    " \n",
    "Retorno\n",
    " - norm: lista con los datos normalizados.\n",
    "'''\n",
    "def normalizacion(lista, maximo, minimo):\n",
    "    norm = []\n",
    "    p = 0\n",
    "    for l in range(len(lista)):\n",
    "        if l % 10 == 0 and l != 0:\n",
    "            p+=1\n",
    "        norm.append((lista[l] - minimo) / (maximo - minimo))\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción de los datos\n",
    "En este paso, las características se almacenarán en formato tabla utilizando dataframes, donde las filas serán las características de cada paciente y las columnas serán el nombre de cada característica. Las características son extraídas a dos archivos:\n",
    "- CSV: que se utilizará para guardar los datos separados por comas para poder entrenar los modelos.\n",
    "- XLSX: que se utilizará simplemente para poder visualizar los datos de una manera más clara.\n",
    "\n",
    "Además, en la propia inserción de las características en el dataframe, se calculará la diferencia de las normalizaciones de máximos y mínimos y la velocidad de apertura en la pinza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se extraen las columnas deseadas de la lista con los datos.\n",
    "\n",
    "'''\n",
    "Parámetros:\n",
    " - lista: estructura con los datos que se desean extraer.\n",
    " - ruta: lugar donde se guardarán los ficheros con los datos extraídos.\n",
    " - columns: columnas que se desean extraer.\n",
    " - header: nombre de las columnas.\n",
    "'''\n",
    "def extraerDatos(df, ruta='../TFG/Outputs/Datos', columns = None):\n",
    "    if columns == None:\n",
    "        columns = ['Max1.', 'Max2.', 'Max3.', 'Max4.', 'Max5.', 'Max6.', 'Max7.', 'Max8.', 'Max9.', 'Max10.', \n",
    "         'Min1.', 'Min2.', 'Min3.', 'Min4.', 'Min5.', 'Min6.', 'Min7.', 'Min8.', 'Min9.', 'Min10.', \n",
    "         'Diff1.', 'Diff2.', 'Diff3.', 'Diff4.', 'Diff5.', 'Diff6.', 'Diff7.', 'Diff8.', 'Diff9.', \n",
    "         'Diff10.', 'Max1. norm.', 'Max2. norm.', 'Max3. norm.', 'Max4. norm.', 'Max5. norm.', \n",
    "         'Max6. norm.', 'Max7. norm.', 'Max8. norm.', 'Max9. norm.', 'Max10. norm.', 'Min1. norm.', \n",
    "         'Min2. norm.', 'Min3. norm.', 'Min4. norm.', 'Min5. norm.', 'Min6. norm.', 'Min7. norm.', \n",
    "         'Min8. norm.', 'Min9. norm.', 'Min10. norm.', 'Diff1. norm.', 'Diff2. norm.', 'Diff3. norm.', \n",
    "         'Diff4. norm.', 'Diff5. norm.', 'Diff6. norm.', 'Diff7. norm.', 'Diff8. norm.', 'Diff9. norm.', \n",
    "         'Diff10. norm.', 'Mean time', 'Mean speed', 'Hand R(0)/L(1)', 'Sex M(0)/W(1)', 'Age', 'Parkinson']\n",
    "        \n",
    "    df.to_csv(ruta + '/datos.csv', sep=';', columns = columns, index=False, encoding='utf-8')\n",
    "    df.to_excel(ruta + '/datos.xlsx', columns = columns, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['Max1.', 'Max2.', 'Max3.', 'Max4.', 'Max5.', 'Max6.', 'Max7.', 'Max8.', 'Max9.', 'Max10.', \n",
    "            'Min1.', 'Min2.', 'Min3.', 'Min4.', 'Min5.', 'Min6.', 'Min7.', 'Min8.', 'Min9.', 'Min10.', \n",
    "            'Diff1.', 'Diff2.', 'Diff3.', 'Diff4.', 'Diff5.', 'Diff6.', 'Diff7.', 'Diff8.', 'Diff9.', \n",
    "            'Diff10.', 'Max1. norm.', 'Max2. norm.', 'Max3. norm.', 'Max4. norm.', 'Max5. norm.', \n",
    "            'Max6. norm.', 'Max7. norm.', 'Max8. norm.', 'Max9. norm.', 'Max10. norm.', 'Min1. norm.', \n",
    "            'Min2. norm.', 'Min3. norm.', 'Min4. norm.', 'Min5. norm.', 'Min6. norm.', 'Min7. norm.', \n",
    "            'Min8. norm.', 'Min9. norm.', 'Min10. norm.', 'Diff1. norm.', 'Diff2. norm.', 'Diff3. norm.', \n",
    "            'Diff4. norm.', 'Diff5. norm.', 'Diff6. norm.', 'Diff7. norm.', 'Diff8. norm.', 'Diff9. norm.', \n",
    "            'Diff10. norm.', 'Mean time', 'Mean speed', 'Hand R(0)/L(1)', 'Sex M(0)/W(1)', 'Age', 'Parkinson']\n",
    "\n",
    "df = pd.DataFrame(columns=columnas)\n",
    "for i in range(32): \n",
    "    lista=[]\n",
    "    norm=[]\n",
    "    velocidades=[]\n",
    "    lista.extend(maximos[i])\n",
    "    lista.extend(minimos[i])\n",
    "    lista.extend(diferencias[i])\n",
    "    max_norm=normalizacion(maximos[i], sorted(maximos[i])[-1], sorted(minimos[i])[0])\n",
    "    min_norm=normalizacion(minimos[i], sorted(maximos[i])[-1], sorted(minimos[i])[0])\n",
    "    lista.extend(max_norm)\n",
    "    lista.extend(min_norm)\n",
    "    for n1,n2 in zip(max_norm, min_norm):\n",
    "        norm.append(n1-n2)\n",
    "    lista.extend(norm)\n",
    "    lista.append(np.mean(tiempos[i]))\n",
    "    for d,t in zip(norm, tiempos[i]):\n",
    "        velocidades.append(d/t)\n",
    "    lista.append(np.mean(velocidades))\n",
    "    lista.append(manos_der_izq[i])\n",
    "    lista.append(sexo[i])\n",
    "    lista.append(edad[i])\n",
    "    lista.append(parkinson[i])\n",
    "    df2 = pd.DataFrame(data = [lista], columns=columnas)\n",
    "    df = pd.concat([df,df2])\n",
    "\n",
    "#extraerDatos(df, columns = ['Max1.', 'Min1.', 'Diff1.', 'Hand R(0)/L(1)'])\n",
    "extraerDatos(df)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
